---
layout: post
title: kubernetes 명령어
date: 2025-05-28 19:00:00 + 0900
categories: [kubernetes]
tags: [kubernetes, k8s]
---
### 책 : 컨테이너 인프라 환경 구축을 위한 쿠버네티스/도커

## 명령어

#### 1. nginx pod 배포
- ```kubectl run nginx --image=nginx```
	
#### 2. pod 확인
- ```kubectl get pod```
	
#### 3. 배포한 pod의 ip 확인
- ```kubectl get pod -o wide```

#### 4. 외부에서 pod에 접근하기 위해 NodePort 방식으로 expose
- ```kubectl expose pod nginx --type=NodePort --port=80```
	- pod가 내부에 있는 container와 통신하기 위한 port: 80
		
#### 5. 노출된 것을 확인
- ```kubectl get service```

#### 6. node에 대한 정보 확인
- ```kubectl get nodes -o wide```

#### 7. nginx를 deploy
- ```kubectl create deployment deploy-nginx --image=nginx```
	
#### 8. nginx를 한 번에 3개 deploy 
- ```kubectl scale deployment deploy-nginx --replicas=3```
	
#### 9. 설정 파일을 이용해 metallb 설치
- ```kubectl apply -f ~/_Lecture_k8s_starter.kit/ch3/3.4/metallb.yaml```

#### 10. chk-hn 레지스트리 deploy	
- ```kubectl create deployment chk-hn --image=sysnet4admin/chk-hn```

#### 11. chk-hn을 한 번에 3개 deploy	
- ```kubectl scale deployment chk-hn --replicas=3```
	
#### 12. 생성한 pods를 expose
- ```kubectl expose deployment chk-hn --type=LoadBalancer --port=80```

#### 13. 배포한 서비스 삭제	
- ```kubectl delete service chk-hn```
- ```kubectl delete service nginx```
	
#### 14. 배포한 deployment 삭제
- ```kubectl delete deployment chk-hn```
- ```kubectl delete deployment deploy-nginx```

#### 15. 배포한 pod 삭제
- ```kubectl delete pod nginx```

#### 16. metallb를 파일로 삭제
- ```kubectl delete -f ~/_Lecture_k8s_starter.kit/ch3/3.4/metallb.yaml```
	
#### 17. 미리 만든 파일로 생성
- ```kubectl apply -f ~/_Lecture_k8s_starter.kit/ch5/5.1```
	- del-deploy.yaml, del-pod.yaml

#### 18. pod 삭제
- ```kubectl delete pod del-pod```
- ```kubectl delete pod del-deploy-d6c48dfbf-wx92z```

#### 19. deploy 삭제
- ```kubectl delete deployment del-deploy```
	
#### 20. 워커노드의 kubelet 중지
- ```systemctl stop kubelet```

#### 21. 워커노드의 kubelet 상태 확인
- ```systemctl status kubelet```

#### 22. 워커노드의 kubelet 실행
- ```systemctl start kubelet```

#### 23. 워커노드의 컨테이너 런타임(containerd) 중지
- ```systemctl stop containerd```

#### 24. 워커노드의 컨테이너 런타임(containerd) 상태 확인
- ```systemctl status containerd```
	
#### 25. 워커노드의 컨테이너 런타임(containerd) 실행
- ```systemctl start containerd```
	
#### 26. 배포된 파드의 세부 값을 확인하는 법
- ```kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName```

#### 27. 인그레스 설정
1. 인그레스 컨트롤러 설치
	- ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.2/ingress-nginx.yaml```
2. 인그레스 리소스 등록
	- ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.2/ingress-config.yaml```
3. 인그레스를 노드포트 서비스로 외부에 노출
	- ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.2/ingress.yaml```
4. deployment를 서비스로 외부에 노출
	- ```kubectl expose deployment in-ip-pod --name=ip-svc --port=80,443```
	- ```kubectl expose deployment in-hname-pod --name=hname-svc-default --port=80,443```

#### 28. 로드밸런서(MetalLB) 설정
1. 로드밸런싱할 deployment 생성
    - ```kubectl create deployment lb-hname-pods --image=sysnet4admin/echo-hname```
    - ```kubectl scale deployment lb-hname-pods --replicas=3```
    - ```kubectl create deployment lb-ip-pods --image=sysnet4admin/echo-ip```
    - ```kubectl scale deployment lb-ip-pods --replicas=3```
2. MetalLB 구성(Controller: 1, Speaker: 4), 확인
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.4/metallb.yaml```
    - ```kubectl get pods -n metallb-system -o wide```
3. ConfigMap으로 MetalLB 설정
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.4/metallb-l2config.yaml```
4. MetalLB 설정 확인
    - ```kubectl get configmap -n metallb-system```
    - ```kubectl get configmap -n metallb-system -0 yaml```
5. 로드밸런서 서비스로 노출
    - ```kubectl expose deployment lb-hname-pods --type=LoadBalancer --name=lb-hname-svc --port=80```
    - ```kubectl expose deployment lb-ip-pods --type=LoadBalancer --name=lb-ip-svc --port=80```
6. 서비스 확인
    - ```kubectl get services```

#### 29. HPA(Horizontal Pod Autoscaler)
1. Autoscale 할 deployment 생성
    - ```kubectl create deployment hpa-hname-pods --image=sysnet4admin/echo-hname```
2. hpa-hname-pods를 로드밸런서 서비스로 설정(MetalLB는 미리 구성한 것으로 간주)
    - ```kubectl expose deployment hpa-hname-pods --type=LoadBalancer --name=hpa-hname-svc --port=80```
3. 메트릭 서버 생성
    - ```kubectl create -f ~/_Book_k8sInfra/ch3/3.3.5/metrics-server.yaml```
4. pod의 top(table of process) 값 확인
    - ```kubectl top pods```
5. scale 기준 값 설정
    - ```kubectl edit deployment hpa-hname-pods```
        - resource: {} 를 아래와 같이 수정
        - 들여쓰기는 tab을 쓰면 안되고 space를 사용
        - m은 milliunits의 약어로 1000m은 1개의 CPU가 됨
        ```
        resources:
            requests:
                cpu: "10m"
            limits:
                cpu: "50m"
        ```
6. hpa-hname-pods에 autoscale 설정
    - ```kubectl autoscale deployment hpa-hname-pods --min=1 --max=30 --cpu-percent=50```

#### 30. PV, PVC 설정
1. PV로 사용할 디렉토리 생성하고 공유 디렉토리 설정
    - ```mkdir /nfs_shared```
    - ```echo '/nfs_shared 192.168.1.0/24(rw,sync,no_root_squash)' >> /etc/exports```

2. NFS 서버를 활성화
    - ```systemctl enable --now nfs```

3. PV 생성, 상태 확인
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.4.3/nfs-pv.yaml```
    - ```kubectl get pv```

4. PVC 생성, 상태 확인
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.4.3/nfs-pvc.yaml```
    - ```kubectl get pvc```

5. PVC를 볼륨으로 사용하는 deployment 배포
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.4.3/nfs-pvc-deploy.yaml```

6. 생성한 파드 중 하나에 exec로 접속해 PVC의 마운트 상태를 확인
    - ```kubectl exec -it nfs-pvc-deploy-5fd9876c46-ppk8z -- /bin/bash```
    - ```df -h```

7. audit-trail 기능 테스트를 위해 expose로 로드밸런서 서비스 생성 후 접속 테스트
    - ```kubectl expose deployment nfs-pvc-deploy --type=LoadBalancer --name=nfs-pvc-deploy-svc --port=80```
    - 브라우저에서 192.168.1.21 접속

8. exec로 접속한 pod에서 접속 기록 확인
    - ```cat /audit/audit_nfs-pvc-deploy-7888b77964-qwwsm.log```

9. 다른 파드 중 하나에 exec로 접속해 접속 기록 확인
    - ```kubectl exec -it nfs-pvc-deploy-5fd9876c46-c6nrp -- /bin/bash```
    - ```cat /audit/audit_nfs-pvc-deploy-7888b77964-qwwsm.log```

#### 31. 스테이트풀셋 설정
1. 스테이트풀셋 생성
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.4.4/nfs-pvc-sts.yaml```

2. 스테이트풀셋을 노출하기 위한 서비스 생성
    - ```kubectl apply -f ~/_Book_k8sInfra/ch3/3.4.4/nfs-pvc-sts-svc.yaml```

3. pod에 접속 정보가 추가됐는지 확인
    - ```kubectl exec -it nfs-pvc-sts-0 -- /bin/bash```
    - ```ls -l /audit```

#### 32. 이미지 검색하고 내려받기
1. nginx 이미지 검색
    - ```docker search nginx```
    - ```docker pull nginx:stable```

2. 내려받은 이미지 조회
    - ```docker images nginx```

3. 이미지가 어떤 과정을 거쳐 생성됐는지 확인
    - ```docker history nginx:stable```
    - ```docker history nginx:latest```

#### 33. 컨테이너 실행
1. 컨테이너 실행
    - ```docker run -d --restart always nginx```
    - -d: --detach, 컨테이너를 백그라운드에서 구동
    - --restart always: 중지된 컨테이너를 즉시 재시작

#### 34. 경로를 설정해 컨테이너를 실행
1. 호스트에 8080으로 들어온 요청을 컨테이너 내부 80포트로 전달하도록 컨테이너 실행
    - ```docker run -d -p 8080:80 --name nginx-exposed --restart always nginx```
    - -p: --publish, 외부에서 보낸 요청을 컨테이너로 전달하는 옵션
    - -p <요청 받을 호스트 포트>:<연결할 컨테이너 포트>

#### 35. 바인드 마운트로 호스트와 컨테이너 연결
1. 연결할 디렉터리를 호스트에 생성
    - mkdir -p /root/html

2. 호스트 디렉터리와 컨테이너 디렉터리를 연결하도록 컨테이너 실행
    - ```docker run -d -p 8081:80 -v /root/html:/usr/share/nginx/html --name nginx-bind-mounts --restart always nginx```
    - -v: --volume, 호스트 디렉터리와 컨테이너 디렉터리를 연결하는 옵션
    - -v <호스트 디렉터리 경로>:<컨테이너 디렉터리 경로>

3. 호스트 디렉터리에 파일 복사
    - ```cp ~/_Book_k8sInfra/ch4/4.2.3/index-BindMount.html /root/html/index.html```

#### 36. 볼륨으로 호스트와 컨테이너 연결
1. 호스트에 볼륨 생성
    - ```docker volume create nginx-volume```

2. 생성된 볼륨 조회
    - ```docker volume inspect nginx-volume```

3. 호스트의 볼륨과 컨테이너 디렉터리를 연결하도록 컨테이너 실행
    - ```docker run -d -p 8082:80 -v nginx-volume:/usr/share/nginx/html --name nginx-volume --restart always nginx```
    - -v <볼륨 이름>:<컨테이너 디렉터리 경로>

4. 볼륨에 파일 복사
    - ```cp ~/_Book_k8sInfra/ch4/4.2.3/index-Volume.html /var/lib/docker/volumes/nginx-volume/_data/index.html```

#### 37. 사용하지 않는 컨테이너 정리
1. 정지할 컨테이너 조회
    - ```docker ps -f ancestor=nginx```

2. 컨테이너 정지
    - ```docker stop tender_snyder```
    - tender_snyder는 컨테이너 이름
    - ```docker stop f350```
    - f350은 컨테이너 ID

3. nginx를 이미지로 사용하는 모든 컨테이너 정지
    - ```docker stop $(docker ps -q -f ancestor=nginx)```
    - ```-q(---quite)``` 옵션은 컨테이너 ID만 출력
    - 명령을 인자로 사용하도록 ```$()```에 넣음

4. 현재 정지된 nginx를 이미지로 사용하는 모든 컨테이너를 삭제
    - ```docker rm $(docker ps -aq -f ancestor=nginx)```

5. 도커 이미지 삭제
    - ```docker rmi $(docker images -q nginx)```

#### 38. 컨테이너 이미지 빌드
1. 빌드 준비
    - java 소스 파일을 빌드하기 위해 jdk, mvnw, Dockerfile이 필요함

2. 빌드
    - ```docker build -t basic-img .```
    - ```-t(tag)```는 만들어질 이미지를 의미하고 ```.```은 이미지에 원하는 내용을 추가하거나 변경하는데 필요한 작업 공간을 현재 디렉터리로 지정한다는 의미
    - Dockerfile에 맞게 빌드를 하고 빌드한 이미지의 이름은 basic-img

3. 빌드 결과 확인
    - ```docker images basic-img```

4. 생성한 컨테이너 이미지를 실행
    - ```docker run -d -p 60431:80 --name basic-run --restart always basic-img```

5. 실행 확인
    - ```docker ps -f name=basic-run```
    - ```curl 127.0.0.1:60431```

6. 컨테이너 이미지 빌드 방법
    - Dockerfile 설정에 따라 기본, 용량 줄이기, 컨테이너 내부 빌드, 멀티 스테이지 등으로 빌드할 수 있다.
    - 용량 줄이기: jdk 이미지 대신 자바 실행을 위한 경령화된 이미지인 distroless를 사용하면 용량을 줄일 수 있다.
    - 컨테이너 내부 빌드: Dockerfile에 빌드할 소스를 git에서 가져와 mvnw를 사용해 jar로 빌드하고 실행 하도록 작성할 수 있다.
        - jar를 빌드하며 생기는 파일들이 컨테이너 이미지에 남아 있어 다른 빌드에 비해 용량이 크다.
    - 멀티 스테이지 빌드: jar를 빌드하는 위치와 최종 이미지를 분리해 컨테이너 이미지 크기를 줄일 수 있다.

7. 댕글링 이미지 삭제
    - 컨테이너 이미지 중 ```<none>```으로 표시되는 이미지가 있는데 멀티 스테이지 과정에서 자바 소스를 빌드하는 과정에서 생성된 이미지이다.
    - ```docker rmi $(docker images -f dangling=true -q)``` 명령어로 댕글링 이미지를 삭제할 수 있다.

#### 39. 쿠버네티스에서 도커 이미지 구동
1. 도커 이미지는 도커 허브에서 받아 오도록 기본적으로 설정되어 있다.
    - 내부에 존재하는 컨테이너 이미지를 사용하기 위해선 이미지 레지스트리를 별도로 만들고 그곳에서 받아오도록 설정해야 한다.
    - 이미지 레지스트리는 쿠버네티스 클러스터가접근할 수 있는 곳에 설치한다.
    - 이미지 레지스트리는 Quay, Harbor, Nexus Repository, Docker Registry가 있다.

2. 도커 레지스트리 설치
    - ```~/_Book_k8sInfra/ch4/4.4.2/create-registry.sh```
    - 도커 레지스트리 컨테이너는 호스트의 8443 포트로 들어온 요청을 컨테이너 내부의 443 포트로 전달한다.
    - 도커 레지스트리의 호스트 IP는 192.168.1.10 

3. 도커 레지스트리에 등록할 수 있게 컨테이너 이미지의 이름을 변경
    - ```docker tag multistage-img 192.168.1.10:8443/multistage-img```

4. 도커 레지스트리에 컨테이너 이미지 등록
    - ```docker push 192.168.1.10:8443/multistage-img```

5. 도커 레지스트리에 이미지 등록을 확인하고 삭제
    - ```curl https://192.168.1.10:8443/v2/_catalog -k```
    - ```docker images | grep multi```로 이미지 ID 확인 후 ```docker rmi -f aa23```으로 삭제한다. 이미지 ID는 aa23이다.

#### 40. Helm으로 MetalLB 설치
1. Helm은 kubectl을 확장해서 복잡환 오브젝트와 구성 환경을 자동으로 맞춰주는 배포 간편화 도구이다.

2. MetalLB 설치
    - ```export DESIRED_VERSION=v3.2.1; ~/_Book_k8sInfra/ch5/5.2.3/helm-install.sh```

3. Helm 차트 저장소를 등록
    - ```helm repo add edu https://iac-source.github.io/helm-charts```

4. 저장소 등록을 확인하고 Helm 저장소 update
    - ```helm repo list```
    - ```helm repo update```

5. 등록한 edu 저장소를 사용해 MetalLB 설치
    - ```helm install metallb edu/metallb --namespace=metallb-system --create-namespace --set controller.tag=v0.8.3 --set speaker.tag=v0.8.3 --set configmap.ipRange=192.168.1.11-192.168.1.29```

6. 설치된 MetalLB가 정상적으로 배포 되었는지 확인
    - ```kubectl get pods -n metallb-system```
    - ```kubectl get configmap -n metallb-system```
    - ```kubectl describe pods -n metallb-system | grep Image:```

7. deployment를 사용해 MetalLB 동작 확인
    - ```kubectl create deployment echo-ip --image=sysnet4admin/echo-ip```
    - ```kubectl expose deployment echo-ip --type=LoadBalancer --port=80```
    - ```kubectl get service echo-ip```
    - ```curl 192.168.11```로 접속 확인
    - ```kubectl delete service & kubectl delete deployment echo-ip``` 명령어로 테스트에 사용한 service와 deployment 삭제

#### 41. Helm으로 젠킨스 설치
1. 도커 레지스트리 설치 확인
    - CI/CD 과정 중에 컨테이너 이미지를 레지스트리에 푸시하기 때문에 도커 레지스트리가 설치되어 있어야 한다.
    - ```docker ps -f name=registry```

2. NFS 디렉터리를 생성
    - 젠킨스는 파드에서 동작하므로 PV를 마운트 하지 않으면 재시작 했을 때 이전 데이터가 삭제된다.
    - 마운트할 호스트의 디렉터리 위치는 ```/nfs_shared```이다.
    - ```~/_Book_k8sInfra/ch5/5.3.1/nfs-exporter.sh jenkins```
    
3. PV가 사용할 NFS 디렉터리에 접근 ID 부여
    - ```chown 1000:1000 /nfs_shared/jenkins/```

4. PV, PVC를 생성하고 확인
    - ```kubectl apply -f ~/_Book_k8sInfra/ch5/5.3.1/jenkins-volume.yaml```
    - ```kubectl get pv jenkins```
    - ```kubectl get pvc jenkins```

5. 젠킨스 설치하고 확인
    - ```~/_Book_k8sInfra/ch5/5.3.1/jenkins-install.sh```
    - ```kubectl get services```
        - jenkins(controller)와 jenkins-agent가 설치되어 있어야 한다.
        - jenkins의 주소는 192.168.1.11 이다. 
    - 브라우저에서 192.168.1.11로 접속해 젠킨스 실행 되었는지 확인한다.

